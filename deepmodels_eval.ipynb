{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms (X) shape: (1754, 1, 2048, 80)\n",
      "Labels (Y) shape: (1754,)\n",
      "Subjects shape: (1754,)\n",
      "Number of samples: 1754\n",
      "Number of classes: 6\n",
      "Test set: (351, 1, 2048, 80), (351,)\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc \n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "x=np.load('datasets/scaled_spec_resampled_array.npy')\n",
    "x =np.reshape(x, (x.shape[0], 1, x.shape[1], x.shape[2]))\n",
    "y=np.load('datasets/labels_array.npy')-1\n",
    "subjects=np.load('datasets/subjects_array.npy')\n",
    "print(f\"Spectrograms (X) shape: {x.shape}\")\n",
    "print(f\"Labels (Y) shape: {y.shape}\")\n",
    "print(f\"Subjects shape: {subjects.shape}\")\n",
    "\n",
    "num_samples = x.shape[0]\n",
    "num_classes = len(np.unique(y))\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Test set: {x_test.shape}, {y_test.shape}\")\n",
    "\n",
    "x_test=torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test=torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            predictions.append(y_pred)\n",
    "    return torch.cat(predictions)\n",
    "\n",
    "def get_scores(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true.cpu().numpy(), y_pred.cpu().numpy())\n",
    "    prec = precision_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average=None)\n",
    "    rec = recall_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average=None)\n",
    "    f1 = f1_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average=None)\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "def print_scores(acc, prec, rec, f1):\n",
    "    activities = ['Walking', 'Sitting Down', 'Standing Up', 'Picking up an Object', 'Drinking Water', 'Falling']\n",
    "    print(f\"Accuracy = {100*acc:.4f}%\")\n",
    "    print(\"Precision:\")\n",
    "    print([f\"{activities[j]}: {100*prec[j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"Recall:\")\n",
    "    print([f\"{activities[j]}: {100*rec[j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"F1:\")\n",
    "    print([f\"{activities[j]}: {100*f1[j]:.2f}%\" for j in range(num_classes)])\n",
    "    print()\n",
    "\n",
    "def print_scores_folds(acc, prec, rec, f1):\n",
    "    activities = ['Walking', 'Sitting Down', 'Standing Up', 'Picking up an Object', 'Drinking Water', 'Falling']\n",
    "    print(f\"Accuracy = {100*np.mean(acc):.4f}%\")\n",
    "    print(\"Precision:\")\n",
    "    print([f\"{activities[j]}: {100*np.mean(prec[:,j]):.2f}%\" for j in range(num_classes)])\n",
    "    print(\"Recall:\")\n",
    "    print([f\"{activities[j]}: {100*np.mean(rec[:,j]):.2f}%\" for j in range(num_classes)])\n",
    "    print(\"F1:\")\n",
    "    print([f\"{activities[j]}: {100*np.mean(f1[:,j]):.2f}%\" for j in range(num_classes)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Vanilla\" ResNets evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.8946%\n",
      "Precision:\n",
      "['Walking: 100.00%', 'Sitting Down: 98.21%', 'Standing Up: 67.82%', 'Picking up an Object: 89.29%', 'Drinking Water: 83.33%', 'Falling: 92.86%']\n",
      "Recall:\n",
      "['Walking: 100.00%', 'Sitting Down: 87.30%', 'Standing Up: 95.16%', 'Picking up an Object: 80.65%', 'Drinking Water: 64.52%', 'Falling: 97.50%']\n",
      "F1:\n",
      "['Walking: 100.00%', 'Sitting Down: 92.44%', 'Standing Up: 79.19%', 'Picking up an Object: 84.75%', 'Drinking Water: 72.73%', 'Falling: 95.12%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=False)\n",
    "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) #change input channels to 1 to use single layer spectrogram images\n",
    "resnet18.fc = nn.Linear(in_features=512, out_features=6, bias=True)\n",
    "\n",
    "resnet18.load_state_dict(torch.load('checkpoints/resnet18.pth'))\n",
    "# resnet18.load_state_dict(torch.load('checkpoints/resnet18.pth', map_location=torch.device('cpu')))\n",
    "resnet18.to(device)\n",
    "\n",
    "test_loader = DataLoader(x_test, batch_size=32, shuffle=False)\n",
    "\n",
    "y_pred = get_predictions(resnet18, test_loader)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "acc, prec, rec, f1 = get_scores(y_test, y_pred)\n",
    "\n",
    "print_scores(acc, prec, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 72.0798%\n",
      "Precision:\n",
      "['Walking: 100.00%', 'Sitting Down: 72.22%', 'Standing Up: 62.67%', 'Picking up an Object: 74.07%', 'Drinking Water: 50.00%', 'Falling: 100.00%']\n",
      "Recall:\n",
      "['Walking: 100.00%', 'Sitting Down: 41.27%', 'Standing Up: 75.81%', 'Picking up an Object: 64.52%', 'Drinking Water: 74.19%', 'Falling: 80.00%']\n",
      "F1:\n",
      "['Walking: 100.00%', 'Sitting Down: 52.53%', 'Standing Up: 68.61%', 'Picking up an Object: 68.97%', 'Drinking Water: 59.74%', 'Falling: 88.89%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resnet34 = models.resnet34(pretrained=False)\n",
    "resnet34.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) #change input channels to 1 to use single layer spectrogram images\n",
    "resnet34.fc = nn.Linear(in_features=512, out_features=6, bias=True)\n",
    "\n",
    "resnet34.load_state_dict(torch.load('checkpoints/resnet34.pth'))\n",
    "# resnet34.load_state_dict(torch.load('checkpoints/resnet34.pth', map_location=torch.device('cpu')))\n",
    "resnet34.to(device)\n",
    "\n",
    "y_pred = get_predictions(resnet34, test_loader)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "acc, prec, rec, f1 = get_scores(y_test, y_pred)\n",
    "\n",
    "print_scores(acc, prec, rec, f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced datasets models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1754, 1, 2048, 80) (1754,)\n",
      "Test set: (351, 1, 2048, 80), (351,)\n"
     ]
    }
   ],
   "source": [
    "x=np.load('datasets/scaled_spec_resampled_array.npy') #load the dataset\n",
    "y=np.load('datasets/labels_array.npy')-1 # labels start from 1, we want them to start from 0\n",
    "x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2]) # add channel dimension for CNN\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(f\"Test set: {x_test.shape}, {y_test.shape}\")\n",
    "\n",
    "x_test=x_test[:,724:1324,:]\n",
    "x_train=x_train[:,724:1324,:]\n",
    "\n",
    "x_test=torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test=torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 7, 7], expected input[32, 0, 2048, 80] to have 1 channels, but got 0 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m resnet18_small\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(x_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet18_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m acc, prec, rec, f1 \u001b[38;5;241m=\u001b[39m get_scores(y_test, y_pred)\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mget_predictions\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      6\u001b[0m         x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 7\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(y_pred)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(predictions)\n",
      "File \u001b[1;32mc:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giaco\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 7, 7], expected input[32, 0, 2048, 80] to have 1 channels, but got 0 channels instead"
     ]
    }
   ],
   "source": [
    "resnet18_small = models.resnet18(pretrained=False)\n",
    "resnet18_small.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) #change input channels to 1 to use single layer spectrogram images\n",
    "resnet18_small.fc = nn.Linear(in_features=512, out_features=6, bias=True)\n",
    "\n",
    "resnet18_small.load_state_dict(torch.load('checkpoints/resnet18_smalldata.pth'))\n",
    "resnet18_small.to(device)\n",
    "\n",
    "test_loader = DataLoader(x_test, batch_size=32, shuffle=False)\n",
    "\n",
    "y_pred = get_predictions(resnet18_small, test_loader)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "acc, prec, rec, f1 = get_scores(y_test, y_pred)\n",
    "\n",
    "print_scores(acc, prec, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.8946%\n",
      "Precision:\n",
      "['Walking: 100.00%', 'Sitting Down: 89.09%', 'Standing Up: 83.82%', 'Picking up an Object: 77.19%', 'Drinking Water: 79.10%', 'Falling: 94.12%']\n",
      "Recall:\n",
      "['Walking: 100.00%', 'Sitting Down: 90.74%', 'Standing Up: 86.36%', 'Picking up an Object: 72.13%', 'Drinking Water: 81.54%', 'Falling: 91.43%']\n",
      "F1:\n",
      "['Walking: 100.00%', 'Sitting Down: 89.91%', 'Standing Up: 85.07%', 'Picking up an Object: 74.58%', 'Drinking Water: 80.30%', 'Falling: 92.75%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resnet34_small = models.resnet34(pretrained=False)\n",
    "resnet34_small.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) #change input channels to 1 to use single layer spectrogram images\n",
    "resnet34_small.fc = nn.Linear(in_features=512, out_features=6, bias=True)\n",
    "\n",
    "resnet34_small.load_state_dict(torch.load('good_checkpoints/resnet34_smalldata.pth'))\n",
    "resnet34_small.to(device)\n",
    "\n",
    "y_pred = get_predictions(resnet34_small, test_loader)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "acc, prec, rec, f1 = get_scores(y_test, y_pred)\n",
    "\n",
    "print_scores(acc, prec, rec, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import GroupKFold\n",
    "FOLDS = 5\n",
    "\n",
    "# Splits for cross-validation:\n",
    "gkf = GroupKFold(n_splits=FOLDS)\n",
    "splits = list(gkf.split(x, y, groups=subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ResNet-18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet18_fold1.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet18_fold2.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet18_fold3.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet18_fold4.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet18_fold5.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint filenames for resnet18:\n",
    "cwd = os.getcwd()\n",
    "base_folder=\"checkpoints/\"\n",
    "fold_paths = [f.path for f in os.scandir(base_folder) if f.is_file() and 'resnet18_fold' in f.name]\n",
    "\n",
    "accuracies = np.zeros(FOLDS)\n",
    "precisions = np.zeros((FOLDS, num_classes))\n",
    "recalls = np.zeros((FOLDS, num_classes))\n",
    "f1s = np.zeros((FOLDS, num_classes))\n",
    "\n",
    "# Fold evaluation loop:\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    print(f\"Evaluating with {fold_paths[i]}...\")\n",
    "\n",
    "    resnet18 = models.resnet18(pretrained=False)\n",
    "    resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    resnet18.fc = nn.Linear(in_features=512, out_features=6, bias=True)\n",
    "\n",
    "    resnet18.load_state_dict(torch.load('checkpoints/resnet18.pth'))\n",
    "    # resnet18.load_state_dict(torch.load(fold_paths[i], map_location=torch.device('cpu')))\n",
    "    resnet18.to(device)\n",
    "\n",
    "    test_loader = DataLoader(x_test, batch_size=32, shuffle=False)\n",
    "    y_pred = get_predictions(resnet18, test_loader)\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    accuracies[i], precisions[i], recalls[i], f1s[i] = get_scores(y_test, y_pred)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 76.3682%\n",
      "Precision:\n",
      "['Walking: 99.09%', 'Sitting Down: 76.55%', 'Standing Up: 69.32%', 'Picking up an Object: 73.17%', 'Drinking Water: 61.23%', 'Falling: 88.95%']\n",
      "Recall:\n",
      "['Walking: 100.00%', 'Sitting Down: 69.66%', 'Standing Up: 77.53%', 'Picking up an Object: 65.59%', 'Drinking Water: 62.02%', 'Falling: 87.18%']\n",
      "F1:\n",
      "['Walking: 99.53%', 'Sitting Down: 72.35%', 'Standing Up: 72.90%', 'Picking up an Object: 68.19%', 'Drinking Water: 61.19%', 'Falling: 87.91%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores_folds(accuracies, precisions, recalls, f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ResNet-34:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet34_fold1.pth...\n",
      "Evaluating with checkpoints/resnet34_fold2.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet34_fold3.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet34_fold4.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with checkpoints/resnet34_fold5.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nickf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint filenames for resnet34:\n",
    "cwd = os.getcwd()\n",
    "base_folder=\"checkpoints/\"\n",
    "fold_paths = [f.path for f in os.scandir(base_folder) if f.is_file() and 'resnet34_fold' in f.name]\n",
    "\n",
    "accuracies = np.zeros(FOLDS)\n",
    "precisions = np.zeros((FOLDS, num_classes))\n",
    "recalls = np.zeros((FOLDS, num_classes))\n",
    "f1s = np.zeros((FOLDS, num_classes))\n",
    "\n",
    "# Fold evaluation loop:\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    print(f\"Evaluating with {fold_paths[i]}...\")\n",
    "\n",
    "    resnet34 = models.resnet34(pretrained=False)\n",
    "    resnet34.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    resnet34.fc = nn.Linear(in_features=512, out_features=6, bias=True)\n",
    "\n",
    "    resnet34.load_state_dict(torch.load('checkpoints/resnet34.pth'))\n",
    "    # resnet34.load_state_dict(torch.load('checkpoints/resnet34.pth', map_location=torch.device('cpu')))\n",
    "    resnet34.to(device)\n",
    "\n",
    "    test_loader = DataLoader(x_test, batch_size=32, shuffle=False)\n",
    "    y_pred = get_predictions(resnet34, test_loader)\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    accuracies[i], precisions[i], recalls[i], f1s[i] = get_scores(y_test, y_pred)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 71.4409%\n",
      "Precision:\n",
      "['Walking: 99.69%', 'Sitting Down: 77.86%', 'Standing Up: 59.18%', 'Picking up an Object: 72.19%', 'Drinking Water: 52.35%', 'Falling: 94.79%']\n",
      "Recall:\n",
      "['Walking: 100.00%', 'Sitting Down: 42.60%', 'Standing Up: 67.18%', 'Picking up an Object: 57.86%', 'Drinking Water: 81.32%', 'Falling: 84.10%']\n",
      "F1:\n",
      "['Walking: 99.84%', 'Sitting Down: 55.00%', 'Standing Up: 62.53%', 'Picking up an Object: 64.16%', 'Drinking Water: 63.39%', 'Falling: 89.05%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores_folds(accuracies, precisions, recalls, f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
