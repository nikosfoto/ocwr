{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we aim to classify the recorded activities using traditional methods, including preprocessing, feature extraction, and classification. Activities include: Walking, Sitting Down, Standing Up, Picking up an Object, Drinking Water, Falling\n",
    "\n",
    "Importing relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms (X) shape: (1754, 2048, 80)\n",
      "Labels (Y) shape: (1754,)\n",
      "Subjects shape: (1754,)\n",
      "Number of samples: 1754\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "x = np.load('datasets/scaled_spec_resampled_array.npy')\n",
    "y = np.load('datasets/labels_array.npy')-1\n",
    "subjects = np.load('datasets/subjects_array.npy')\n",
    "activities = ['Walking', 'Sitting Down', 'Standing Up', 'Picking up an Object', 'Drinking Water', 'Falling']\n",
    "\n",
    "print(f\"Spectrograms (X) shape: {x.shape}\")\n",
    "print(f\"Labels (Y) shape: {y.shape}\")\n",
    "print(f\"Subjects shape: {subjects.shape}\")\n",
    "\n",
    "num_samples = x.shape[0]\n",
    "num_classes = len(np.unique(y))\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing and Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfft = 2048\n",
    "fs = 128000\n",
    "f_lo = -64000.0     # Obtained from dataset_creation.ipynb\n",
    "f_hi = 63937.5\n",
    "\n",
    "freq_axis = np.linspace(f_lo, f_hi, nfft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising and feature extraction based on this paper:\n",
    "\n",
    "Y. Kim and H. Ling, \"Human Activity Classification Based on Micro-Doppler Signatures Using a Support Vector Machine,\" in IEEE Transactions on Geoscience and Remote Sensing, vol. 47, no. 5, pp. 1328-1337, May 2009\n",
    "\n",
    "Features extracted:\n",
    "\n",
    "(1) Torso Doppler frequency: Indicates the speed of the human subject.\n",
    "\n",
    "(2) Total bandwidth (BW) of the Doppler signal: Relates to the speed of limb motions.\n",
    "\n",
    "(3) Offset of the total Doppler signal: Measures asymmetry between forward and backward limb motions.\n",
    "\n",
    "(4) BW without micro-Dopplers: Represents the Doppler bandwidth of the torso alone.\n",
    "\n",
    "(5) Normalized standard deviation (STD) of the Doppler signal strength: Related to the dynamic range of the motion.\n",
    "\n",
    "(6) Period of limb motion: Corresponds to the swing rate of arms and legs.\n",
    "\n",
    "\n",
    "Also added 2 other features:\n",
    "\n",
    "(7) Entropy: How dispersed is the energy across frequencies.\n",
    "\n",
    "(8) High envelope standard deviation: Can indicate different types of motion. For instance, it could be used to identify the spectrogram peaks when picking up an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_and_extract_features(frequencies, spectrogram, noise_threshold):\n",
    "    # Initialize feature variables\n",
    "    torso_doppler_frequency = []\n",
    "    total_bw_doppler = []\n",
    "    offset_total_doppler = []\n",
    "    bw_without_micro_dopplers = []\n",
    "    normalized_std_doppler = []\n",
    "    entropies = []\n",
    "    high_envelope = []\n",
    "    low_envelope = []\n",
    "    # Denoise spectrogram\n",
    "    spec_denoised = np.where(spectrogram < noise_threshold, noise_threshold, spectrogram)\n",
    "    for t_index in range(spec_denoised.shape[1]):\n",
    "\n",
    "        column = spec_denoised[:, t_index]\n",
    "        \n",
    "        if np.all(column == noise_threshold):   # If the entire column is noise\n",
    "            high_freq = 0\n",
    "            low_freq = 0\n",
    "            peak_freq = 0\n",
    "            total_bw = 0\n",
    "            offset_total = 0\n",
    "            normalized_std = 0\n",
    "            entr = 0\n",
    "        else:   # If the column contains signal\n",
    "            high_freq = frequencies[column > noise_threshold][-1]\n",
    "            low_freq = frequencies[column > noise_threshold][0]\n",
    "            # Torso Doppler Frequency (1)\n",
    "            peak_freq = frequencies[np.argmax(column)]\n",
    "            # Total Bandwidth of the Doppler Signal (2)\n",
    "            total_bw = high_freq-low_freq\n",
    "            # Offset of the Total Doppler (3)\n",
    "            offset_total = (high_freq + low_freq) / 2\n",
    "            # Normalized STD of the Doppler Signal Strength (5)\n",
    "            std_doppler = np.std(column)\n",
    "            mean_doppler = np.mean(column)\n",
    "            normalized_std = std_doppler / mean_doppler if mean_doppler != 0 else 0\n",
    "            # New feature: Entropy (7)\n",
    "            entr = entropy(column)\n",
    "\n",
    "        high_envelope.append(high_freq)\n",
    "        low_envelope.append(low_freq)\n",
    "        torso_doppler_frequency.append(peak_freq)\n",
    "        total_bw_doppler.append(total_bw)\n",
    "        offset_total_doppler.append(offset_total)\n",
    "        normalized_std_doppler.append(normalized_std)\n",
    "        entropies.append(entr)\n",
    "\n",
    "    # Bandwidth Without Micro-Dopplers (4)\n",
    "    bw_without_micro_dopplers = np.mean(np.array(sorted(high_envelope)[-5:]) - np.array(sorted(low_envelope)[:5]))\n",
    "\n",
    "    # Period of Limb Motion (6)\n",
    "    peaks, _ = find_peaks(high_envelope, height=np.nanmean(high_envelope))\n",
    "    peak_intervals = np.diff(peaks)\n",
    "    periods = peak_intervals / fs\n",
    "    mean_period = np.mean(periods) if len(periods) > 0 else 0\n",
    "\n",
    "    # New feature: Peak frequency standard deviation (8)\n",
    "    peak_freq_variation = np.std(high_envelope)\n",
    "\n",
    "    return [np.mean(torso_doppler_frequency),\n",
    "            np.mean(total_bw_doppler),\n",
    "            np.mean(offset_total_doppler),\n",
    "            bw_without_micro_dopplers,\n",
    "            np.mean(normalized_std_doppler),\n",
    "            mean_period,\n",
    "            np.mean(entropies),\n",
    "            peak_freq_variation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract these features from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1754, 8)\n"
     ]
    }
   ],
   "source": [
    "noise_threshold = -83  # dBm (based on the paper's noise threshold)\n",
    "features = []\n",
    "for i in range(num_samples):\n",
    "    features.append(denoise_and_extract_features(freq_axis, x[i,:,:], noise_threshold))\n",
    "features = np.array(features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the most important features by measuring the mutual information among the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI between target and feature 1: 0.9180\n",
      "MI between target and feature 2: 0.4555\n",
      "MI between target and feature 3: 0.6908\n",
      "MI between target and feature 4: 0.3872\n",
      "MI between target and feature 5: 0.5082\n",
      "MI between target and feature 6: 0.1052\n",
      "MI between target and feature 7: 0.6996\n",
      "MI between target and feature 8: 0.2877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mutual_infos = mutual_info_classif(X=features, y=y)\n",
    "for feature, mi in enumerate(mutual_infos, start=1):\n",
    "    print(f\"MI between target and feature {feature}: {mi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature number 6 (Period of Limb Motion) appears to be the least important, as it has the lowest mutual information score with the label vector among all the features. Given its low contribution, we can consider removing this feature from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[:, [0, 1, 2, 3, 4, 6, 7]]  # Remove period of limb motion (feature 6 - index 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted the features, it is time to split the dataset. Due to the limited dataset size, we chose to perform 5-fold cross-validation to obtain a more accurate estimate of each model's performance.\n",
    "\n",
    "We also note that each of these 5 folds contains activities performed by different subjects, with no overlap across folds. In other words, in each iteration, the test set contains activities from subjects not used in training. This approach simulates a realistic scenario, as in the real world, the subjects in the test set are not seen by the model during training.\n",
    "\n",
    "It's also important to note that the number of activities performed varies across subjects, i.e. some subjects have performed more repetitions than others (see code block below). We account for this variation when splitting the data, resulting in 5 roughly equal folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 8 performed 36 activities\n",
      "Subject 14 performed 36 activities\n",
      "Subject 57 performed 36 activities\n",
      "Subject 30 performed 34 activities\n",
      "Subject 53 performed 34 activities\n",
      "Subject 28 performed 33 activities\n",
      "Subject 29 performed 33 activities\n",
      "Subject 31 performed 33 activities\n",
      "Subject 32 performed 33 activities\n",
      "Subject 33 performed 33 activities\n",
      "Subject 34 performed 33 activities\n",
      "Subject 36 performed 33 activities\n",
      "Subject 37 performed 33 activities\n",
      "Subject 38 performed 33 activities\n",
      "Subject 39 performed 33 activities\n",
      "Subject 40 performed 33 activities\n",
      "Subject 41 performed 33 activities\n",
      "Subject 43 performed 33 activities\n",
      "Subject 44 performed 33 activities\n",
      "Subject 45 performed 33 activities\n",
      "Subject 46 performed 33 activities\n",
      "Subject 47 performed 33 activities\n",
      "Subject 50 performed 33 activities\n",
      "Subject 51 performed 33 activities\n",
      "Subject 52 performed 33 activities\n",
      "Subject 55 performed 33 activities\n",
      "Subject 56 performed 33 activities\n",
      "Subject 35 performed 32 activities\n",
      "Subject 54 performed 32 activities\n",
      "Subject 3 performed 31 activities\n",
      "Subject 11 performed 30 activities\n",
      "Subject 12 performed 30 activities\n",
      "Subject 10 performed 29 activities\n",
      "Subject 42 performed 22 activities\n",
      "Subject 64 performed 19 activities\n",
      "Subject 1 performed 18 activities\n",
      "Subject 2 performed 18 activities\n",
      "Subject 4 performed 18 activities\n",
      "Subject 5 performed 18 activities\n",
      "Subject 6 performed 18 activities\n",
      "Subject 7 performed 18 activities\n",
      "Subject 9 performed 18 activities\n",
      "Subject 13 performed 18 activities\n",
      "Subject 15 performed 18 activities\n",
      "Subject 16 performed 18 activities\n",
      "Subject 17 performed 18 activities\n",
      "Subject 58 performed 18 activities\n",
      "Subject 59 performed 18 activities\n",
      "Subject 60 performed 18 activities\n",
      "Subject 61 performed 18 activities\n",
      "Subject 62 performed 18 activities\n",
      "Subject 65 performed 18 activities\n",
      "Subject 66 performed 18 activities\n",
      "Subject 67 performed 18 activities\n",
      "Subject 68 performed 18 activities\n",
      "Subject 69 performed 18 activities\n",
      "Subject 70 performed 18 activities\n",
      "Subject 71 performed 18 activities\n",
      "Subject 72 performed 18 activities\n",
      "Subject 63 performed 17 activities\n",
      "Subject 18 performed 15 activities\n",
      "Subject 19 performed 15 activities\n",
      "Subject 20 performed 15 activities\n",
      "Subject 22 performed 15 activities\n",
      "Subject 24 performed 15 activities\n",
      "Subject 25 performed 15 activities\n",
      "Subject 26 performed 15 activities\n",
      "Subject 27 performed 15 activities\n",
      "Subject 48 performed 15 activities\n",
      "Subject 49 performed 15 activities\n",
      "Subject 21 performed 14 activities\n",
      "Subject 23 performed 14 activities\n"
     ]
    }
   ],
   "source": [
    "# Number of activities different per subject\n",
    "unique, counts = np.unique(subjects, return_counts=True)\n",
    "subject_counts = dict(zip(unique, counts))\n",
    "sorted_subject_counts = dict(sorted(subject_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "for key, value in sorted_subject_counts.items():\n",
    "    print(f\"Subject {key} performed {value} activities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in roughly 5 equal folds, ensuring that each subject is present in only in one fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "Length of training set: 1398 samples\n",
      "Length of testing set (fold): 356 samples\n",
      "Unique subjects in fold 1: [ 4 16 20 23 25 28 32 38 42 46 54 57 58 60 67]\n",
      "\n",
      "Fold 2:\n",
      "Length of training set: 1401 samples\n",
      "Length of testing set (fold): 353 samples\n",
      "Unique subjects in fold 2: [ 5  8  9 19 21 31 35 39 45 49 52 61 64 68 72]\n",
      "\n",
      "Fold 3:\n",
      "Length of training set: 1405 samples\n",
      "Length of testing set (fold): 349 samples\n",
      "Unique subjects in fold 3: [ 2  3  7 11 14 18 26 29 37 44 55 65 70 71]\n",
      "\n",
      "Fold 4:\n",
      "Length of training set: 1406 samples\n",
      "Length of testing set (fold): 348 samples\n",
      "Unique subjects in fold 4: [ 6 12 17 22 34 36 43 47 48 53 56 62 63 69]\n",
      "\n",
      "Fold 5:\n",
      "Length of training set: 1406 samples\n",
      "Length of testing set (fold): 348 samples\n",
      "Unique subjects in fold 5: [ 1 10 13 15 24 27 30 33 40 41 50 51 59 66]\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "splits = list(gkf.split(x, y, groups=subjects))\n",
    "\n",
    "# Verification:\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(f\"\\nFold {i+1}:\")\n",
    "    print(f\"Length of training set: {len(train_index)} samples\")\n",
    "    print(f\"Length of testing set (fold): {len(test_index)} samples\")\n",
    "    print(f\"Unique subjects in fold {i+1}: {np.unique(subjects[test_index])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to the classification. We try KNN, Random Forests, XGBoost and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1...\n",
      "Fold 2...\n",
      "Fold 3...\n",
      "Fold 4...\n",
      "Fold 5...\n",
      "Done!\n",
      "\n",
      "For k = 1:\n",
      "KNN mean accuracy = 75.55%\n",
      "KNN precisions per activity:\n",
      "['Walking: 97.54%', 'Sitting Down: 89.11%', 'Standing Up: 85.36%', 'Picking up an Object: 50.87%', 'Drinking Water: 50.05%', 'Falling: 87.67%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 98.10%', 'Sitting Down: 85.58%', 'Standing Up: 80.72%', 'Picking up an Object: 53.11%', 'Drinking Water: 50.67%', 'Falling: 90.35%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.79%', 'Sitting Down: 87.19%', 'Standing Up: 82.82%', 'Picking up an Object: 51.82%', 'Drinking Water: 50.23%', 'Falling: 88.87%']\n",
      "\n",
      "For k = 2:\n",
      "KNN mean accuracy = 74.63%\n",
      "KNN precisions per activity:\n",
      "['Walking: 96.74%', 'Sitting Down: 81.04%', 'Standing Up: 78.60%', 'Picking up an Object: 49.33%', 'Drinking Water: 51.52%', 'Falling: 94.18%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 90.38%', 'Standing Up: 87.46%', 'Picking up an Object: 61.48%', 'Drinking Water: 29.65%', 'Falling: 81.78%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.99%', 'Sitting Down: 85.39%', 'Standing Up: 82.74%', 'Picking up an Object: 54.71%', 'Drinking Water: 37.59%', 'Falling: 87.51%']\n",
      "\n",
      "For k = 3:\n",
      "KNN mean accuracy = 76.00%\n",
      "KNN precisions per activity:\n",
      "['Walking: 96.74%', 'Sitting Down: 83.43%', 'Standing Up: 85.26%', 'Picking up an Object: 53.68%', 'Drinking Water: 51.74%', 'Falling: 88.02%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 87.18%', 'Standing Up: 84.26%', 'Picking up an Object: 51.42%', 'Drinking Water: 48.74%', 'Falling: 89.91%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.99%', 'Sitting Down: 85.18%', 'Standing Up: 84.45%', 'Picking up an Object: 52.34%', 'Drinking Water: 49.97%', 'Falling: 88.88%']\n",
      "\n",
      "For k = 4:\n",
      "KNN mean accuracy = 77.37%\n",
      "KNN precisions per activity:\n",
      "['Walking: 97.04%', 'Sitting Down: 89.20%', 'Standing Up: 86.98%', 'Picking up an Object: 53.18%', 'Drinking Water: 56.27%', 'Falling: 88.22%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 87.82%', 'Standing Up: 83.63%', 'Picking up an Object: 63.00%', 'Drinking Water: 46.78%', 'Falling: 86.75%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 98.15%', 'Sitting Down: 88.36%', 'Standing Up: 84.84%', 'Picking up an Object: 57.59%', 'Drinking Water: 50.79%', 'Falling: 87.42%']\n",
      "\n",
      "For k = 5:\n",
      "KNN mean accuracy = 77.54%\n",
      "KNN precisions per activity:\n",
      "['Walking: 97.03%', 'Sitting Down: 89.91%', 'Standing Up: 86.41%', 'Picking up an Object: 53.93%', 'Drinking Water: 56.13%', 'Falling: 86.25%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.06%', 'Sitting Down: 89.76%', 'Standing Up: 83.00%', 'Picking up an Object: 57.81%', 'Drinking Water: 50.97%', 'Falling: 88.27%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.98%', 'Sitting Down: 89.75%', 'Standing Up: 84.51%', 'Picking up an Object: 55.64%', 'Drinking Water: 53.20%', 'Falling: 87.22%']\n",
      "\n",
      "For k = 6:\n",
      "KNN mean accuracy = 77.66%\n",
      "KNN precisions per activity:\n",
      "['Walking: 96.72%', 'Sitting Down: 90.35%', 'Standing Up: 87.35%', 'Picking up an Object: 54.47%', 'Drinking Water: 55.68%', 'Falling: 85.98%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 89.46%', 'Standing Up: 82.03%', 'Picking up an Object: 61.69%', 'Drinking Water: 48.39%', 'Falling: 88.78%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.98%', 'Sitting Down: 89.82%', 'Standing Up: 84.34%', 'Picking up an Object: 57.74%', 'Drinking Water: 51.64%', 'Falling: 87.31%']\n",
      "\n",
      "For k = 7:\n",
      "KNN mean accuracy = 77.60%\n",
      "KNN precisions per activity:\n",
      "['Walking: 96.72%', 'Sitting Down: 93.42%', 'Standing Up: 88.86%', 'Picking up an Object: 54.05%', 'Drinking Water: 55.33%', 'Falling: 83.20%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 87.49%', 'Standing Up: 80.42%', 'Picking up an Object: 62.31%', 'Drinking Water: 50.63%', 'Falling: 89.31%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.98%', 'Sitting Down: 90.23%', 'Standing Up: 84.30%', 'Picking up an Object: 57.75%', 'Drinking Water: 52.75%', 'Falling: 86.11%']\n",
      "\n",
      "For k = 8:\n",
      "KNN mean accuracy = 77.31%\n",
      "KNN precisions per activity:\n",
      "['Walking: 96.72%', 'Sitting Down: 92.72%', 'Standing Up: 87.40%', 'Picking up an Object: 53.12%', 'Drinking Water: 56.89%', 'Falling: 83.63%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 86.86%', 'Standing Up: 80.07%', 'Picking up an Object: 62.63%', 'Drinking Water: 49.68%', 'Falling: 89.31%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.98%', 'Sitting Down: 89.58%', 'Standing Up: 83.42%', 'Picking up an Object: 57.36%', 'Drinking Water: 52.84%', 'Falling: 86.33%']\n",
      "\n",
      "For k = 9:\n",
      "KNN mean accuracy = 77.15%\n",
      "KNN precisions per activity:\n",
      "['Walking: 96.42%', 'Sitting Down: 92.26%', 'Standing Up: 87.47%', 'Picking up an Object: 54.40%', 'Drinking Water: 56.33%', 'Falling: 82.04%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 98.74%', 'Sitting Down: 86.88%', 'Standing Up: 78.79%', 'Picking up an Object: 61.72%', 'Drinking Water: 52.26%', 'Falling: 88.28%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.52%', 'Sitting Down: 89.35%', 'Standing Up: 82.73%', 'Picking up an Object: 57.72%', 'Drinking Water: 54.04%', 'Falling: 84.97%']\n",
      "\n",
      "For k = 10:\n",
      "KNN mean accuracy = 77.26%\n",
      "KNN precisions per activity:\n",
      "['Walking: 96.72%', 'Sitting Down: 91.97%', 'Standing Up: 88.68%', 'Picking up an Object: 53.50%', 'Drinking Water: 58.19%', 'Falling: 81.43%']\n",
      "KNN recalls per activity:\n",
      "['Walking: 99.06%', 'Sitting Down: 86.56%', 'Standing Up: 78.13%', 'Picking up an Object: 62.64%', 'Drinking Water: 51.91%', 'Falling: 89.31%']\n",
      "KNN F1 scores per activity:\n",
      "['Walking: 97.82%', 'Sitting Down: 88.97%', 'Standing Up: 82.83%', 'Picking up an Object: 57.60%', 'Drinking Water: 54.49%', 'Falling: 85.13%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_values = np.arange(1,11)\n",
    "accuracies = np.zeros((5, len(k_values)))\n",
    "precisions = np.zeros((5, len(k_values), num_classes))\n",
    "recalls = np.zeros((5, len(k_values), num_classes))\n",
    "f1_scores = np.zeros((5, len(k_values), num_classes))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(f\"Fold {i+1}...\")\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(x_train, y_train)\n",
    "        y_pred = knn.predict(x_test)\n",
    "        accuracies[i,k-1] = accuracy_score(y_test, y_pred)\n",
    "        precisions[i,k-1,:] = precision_score(y_test, y_pred, average=None)\n",
    "        recalls[i,k-1,:] = recall_score(y_test, y_pred, average=None)\n",
    "        f1_scores[i,k-1,:] = f1_score(y_test, y_pred, average=None)\n",
    "print(\"Done!\\n\")\n",
    "\n",
    "mean_accuracies = np.mean(accuracies, axis=0)\n",
    "mean_precisions = np.mean(precisions, axis=0)\n",
    "mean_recalls = np.mean(recalls, axis=0)\n",
    "mean_f1_scores = np.mean(f1_scores, axis=0)\n",
    "\n",
    "# Print the scores for each k\n",
    "for i in range(len(k_values)):\n",
    "    print(f\"For k = {k_values[i]}:\")\n",
    "    print(f\"KNN mean accuracy = {100*mean_accuracies[i]:.2f}%\")\n",
    "    print(\"KNN precisions per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_precisions[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"KNN recalls per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_recalls[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"KNN F1 scores per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_f1_scores[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1...\n",
      "Fold 2...\n",
      "Fold 3...\n",
      "Fold 4...\n",
      "Fold 5...\n",
      "Done!\n",
      "\n",
      "For 10 trees:\n",
      "RF mean accuracy = 82.63%\n",
      "RF precisions per activity:\n",
      "['Walking: 99.37%', 'Sitting Down: 94.14%', 'Standing Up: 88.49%', 'Picking up an Object: 63.14%', 'Drinking Water: 63.79%', 'Falling: 90.37%']\n",
      "RF recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 93.91%', 'Standing Up: 89.73%', 'Picking up an Object: 64.00%', 'Drinking Water: 59.41%', 'Falling: 92.83%']\n",
      "RF F1 scores per activity:\n",
      "['Walking: 99.37%', 'Sitting Down: 93.94%', 'Standing Up: 88.68%', 'Picking up an Object: 63.44%', 'Drinking Water: 61.42%', 'Falling: 91.13%']\n",
      "\n",
      "For 100 trees:\n",
      "RF mean accuracy = 83.93%\n",
      "RF precisions per activity:\n",
      "['Walking: 99.37%', 'Sitting Down: 93.94%', 'Standing Up: 91.73%', 'Picking up an Object: 66.45%', 'Drinking Water: 64.34%', 'Falling: 91.77%']\n",
      "RF recalls per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 93.27%', 'Standing Up: 90.39%', 'Picking up an Object: 65.65%', 'Drinking Water: 63.23%', 'Falling: 95.45%']\n",
      "RF F1 scores per activity:\n",
      "['Walking: 99.53%', 'Sitting Down: 93.54%', 'Standing Up: 90.80%', 'Picking up an Object: 65.94%', 'Drinking Water: 63.75%', 'Falling: 93.10%']\n",
      "\n",
      "For 250 trees:\n",
      "RF mean accuracy = 84.16%\n",
      "RF precisions per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 94.58%', 'Standing Up: 92.42%', 'Picking up an Object: 66.10%', 'Drinking Water: 63.65%', 'Falling: 93.65%']\n",
      "RF recalls per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 93.27%', 'Standing Up: 90.70%', 'Picking up an Object: 64.34%', 'Drinking Water: 65.50%', 'Falling: 95.45%']\n",
      "RF F1 scores per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 93.85%', 'Standing Up: 91.28%', 'Picking up an Object: 65.11%', 'Drinking Water: 64.52%', 'Falling: 94.26%']\n",
      "\n",
      "For 500 trees:\n",
      "RF mean accuracy = 84.10%\n",
      "RF precisions per activity:\n",
      "['Walking: 99.37%', 'Sitting Down: 94.97%', 'Standing Up: 92.21%', 'Picking up an Object: 65.28%', 'Drinking Water: 64.38%', 'Falling: 93.11%']\n",
      "RF recalls per activity:\n",
      "['Walking: 99.06%', 'Sitting Down: 93.59%', 'Standing Up: 90.38%', 'Picking up an Object: 65.63%', 'Drinking Water: 64.50%', 'Falling: 95.45%']\n",
      "RF F1 scores per activity:\n",
      "['Walking: 99.20%', 'Sitting Down: 94.20%', 'Standing Up: 91.08%', 'Picking up an Object: 65.34%', 'Drinking Water: 64.40%', 'Falling: 94.00%']\n",
      "\n",
      "For 1000 trees:\n",
      "RF mean accuracy = 83.88%\n",
      "RF precisions per activity:\n",
      "['Walking: 99.37%', 'Sitting Down: 94.68%', 'Standing Up: 92.00%', 'Picking up an Object: 65.22%', 'Drinking Water: 64.01%', 'Falling: 92.61%']\n",
      "RF recalls per activity:\n",
      "['Walking: 99.06%', 'Sitting Down: 93.28%', 'Standing Up: 90.06%', 'Picking up an Object: 64.99%', 'Drinking Water: 64.53%', 'Falling: 95.45%']\n",
      "RF F1 scores per activity:\n",
      "['Walking: 99.20%', 'Sitting Down: 93.90%', 'Standing Up: 90.77%', 'Picking up an Object: 65.04%', 'Drinking Water: 64.23%', 'Falling: 93.75%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_values = [10, 100, 250, 500, 1000]\n",
    "accuracies = np.zeros((5, len(tree_values)))\n",
    "precisions = np.zeros((5, len(tree_values), num_classes))\n",
    "recalls = np.zeros((5, len(tree_values), num_classes))\n",
    "f1_scores = np.zeros((5, len(tree_values), num_classes))\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(f\"Fold {i+1}...\")\n",
    "    for j, trees in enumerate(tree_values):\n",
    "        rf = RandomForestClassifier(n_estimators=trees)\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        accuracies[i,j] = accuracy_score(y_test, y_pred)\n",
    "        precisions[i,j,:] = precision_score(y_test, y_pred, average=None, labels=np.unique(y_pred))\n",
    "        recalls[i,j,:] = recall_score(y_test, y_pred, average=None, labels=np.unique(y_pred))\n",
    "        f1_scores[i,j,:] = f1_score(y_test, y_pred, average=None, labels=np.unique(y_pred))\n",
    "print(\"Done!\\n\")\n",
    "\n",
    "mean_accuracies = np.mean(accuracies, axis=0)\n",
    "mean_precisions = np.mean(precisions, axis=0)\n",
    "mean_recalls = np.mean(recalls, axis=0)\n",
    "mean_f1_scores = np.mean(f1_scores, axis=0)\n",
    "\n",
    "# Print the scores for each tree number\n",
    "for i in range(len(tree_values)):\n",
    "    print(f\"For {tree_values[i]} trees:\")\n",
    "    print(f\"RF mean accuracy = {100*mean_accuracies[i]:.2f}%\")\n",
    "    print(\"RF precisions per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_precisions[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"RF recalls per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_recalls[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"RF F1 scores per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_f1_scores[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1...\n",
      "Fold 2...\n",
      "Fold 3...\n",
      "Fold 4...\n",
      "Fold 5...\n",
      "Done!\n",
      "\n",
      "For 10 trees:\n",
      "XGBoost mean accuracy = 84.50%\n",
      "XGBoost precisions per activity:\n",
      "['Walking: 99.36%', 'Sitting Down: 94.53%', 'Standing Up: 91.62%', 'Picking up an Object: 67.45%', 'Drinking Water: 65.30%', 'Falling: 92.69%']\n",
      "XGBoost recalls per activity:\n",
      "['Walking: 100.00%', 'Sitting Down: 93.91%', 'Standing Up: 91.03%', 'Picking up an Object: 62.71%', 'Drinking Water: 68.73%', 'Falling: 93.95%']\n",
      "XGBoost F1 scores per activity:\n",
      "['Walking: 99.68%', 'Sitting Down: 94.20%', 'Standing Up: 91.20%', 'Picking up an Object: 64.94%', 'Drinking Water: 66.90%', 'Falling: 92.91%']\n",
      "\n",
      "For 100 trees:\n",
      "XGBoost mean accuracy = 84.10%\n",
      "XGBoost precisions per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 94.18%', 'Standing Up: 91.78%', 'Picking up an Object: 66.34%', 'Drinking Water: 64.30%', 'Falling: 93.52%']\n",
      "XGBoost recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 92.01%', 'Standing Up: 92.30%', 'Picking up an Object: 64.30%', 'Drinking Water: 66.13%', 'Falling: 93.89%']\n",
      "XGBoost F1 scores per activity:\n",
      "['Walking: 99.53%', 'Sitting Down: 92.98%', 'Standing Up: 91.92%', 'Picking up an Object: 65.18%', 'Drinking Water: 65.10%', 'Falling: 93.16%']\n",
      "\n",
      "For 250 trees:\n",
      "XGBoost mean accuracy = 83.47%\n",
      "XGBoost precisions per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 93.54%', 'Standing Up: 92.07%', 'Picking up an Object: 64.48%', 'Drinking Water: 62.77%', 'Falling: 93.52%']\n",
      "XGBoost recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 92.01%', 'Standing Up: 92.30%', 'Picking up an Object: 62.74%', 'Drinking Water: 64.18%', 'Falling: 93.89%']\n",
      "XGBoost F1 scores per activity:\n",
      "['Walking: 99.53%', 'Sitting Down: 92.68%', 'Standing Up: 92.07%', 'Picking up an Object: 63.47%', 'Drinking Water: 63.35%', 'Falling: 93.16%']\n",
      "\n",
      "For 500 trees:\n",
      "XGBoost mean accuracy = 83.30%\n",
      "XGBoost precisions per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 94.12%', 'Standing Up: 92.01%', 'Picking up an Object: 63.27%', 'Drinking Water: 62.61%', 'Falling: 93.41%']\n",
      "XGBoost recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 92.01%', 'Standing Up: 92.30%', 'Picking up an Object: 63.05%', 'Drinking Water: 63.21%', 'Falling: 93.37%']\n",
      "XGBoost F1 scores per activity:\n",
      "['Walking: 99.53%', 'Sitting Down: 92.97%', 'Standing Up: 92.07%', 'Picking up an Object: 63.06%', 'Drinking Water: 62.78%', 'Falling: 92.91%']\n",
      "\n",
      "For 1000 trees:\n",
      "XGBoost mean accuracy = 83.07%\n",
      "XGBoost precisions per activity:\n",
      "['Walking: 99.69%', 'Sitting Down: 93.54%', 'Standing Up: 92.03%', 'Picking up an Object: 62.59%', 'Drinking Water: 62.12%', 'Falling: 93.41%']\n",
      "XGBoost recalls per activity:\n",
      "['Walking: 99.38%', 'Sitting Down: 92.33%', 'Standing Up: 92.63%', 'Picking up an Object: 61.12%', 'Drinking Water: 63.20%', 'Falling: 93.37%']\n",
      "XGBoost F1 scores per activity:\n",
      "['Walking: 99.53%', 'Sitting Down: 92.84%', 'Standing Up: 92.23%', 'Picking up an Object: 61.76%', 'Drinking Water: 62.52%', 'Falling: 92.91%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "tree_values = [10, 100, 250, 500, 1000]\n",
    "accuracies = np.zeros((5, len(tree_values)))\n",
    "precisions = np.zeros((5, len(tree_values), num_classes))\n",
    "recalls = np.zeros((5, len(tree_values), num_classes))\n",
    "f1_scores = np.zeros((5, len(tree_values), num_classes))\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(f\"Fold {i+1}...\")\n",
    "    for j, trees in enumerate(tree_values):\n",
    "        xgb = XGBClassifier(n_estimators=trees)\n",
    "        xgb.fit(x_train, y_train)\n",
    "        y_pred = xgb.predict(x_test)\n",
    "        accuracies[i,j] = accuracy_score(y_test, y_pred)\n",
    "        precisions[i,j] = precision_score(y_test, y_pred, average=None)\n",
    "        recalls[i,j] = recall_score(y_test, y_pred, average=None)\n",
    "        f1_scores[i,j] = f1_score(y_test, y_pred, average=None)\n",
    "print(\"Done!\\n\")\n",
    "\n",
    "mean_accuracies = np.mean(accuracies, axis=0)\n",
    "mean_precisions = np.mean(precisions, axis=0)\n",
    "mean_recalls = np.mean(recalls, axis=0)\n",
    "mean_f1_scores = np.mean(f1_scores, axis=0)\n",
    "\n",
    "# Print the scores for each tree number\n",
    "for i in range(len(tree_values)):\n",
    "    print(f\"For {tree_values[i]} trees:\")\n",
    "    print(f\"XGBoost mean accuracy = {100*mean_accuracies[i]:.2f}%\")\n",
    "    print(\"XGBoost precisions per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_precisions[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"XGBoost recalls per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_recalls[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"XGBoost F1 scores per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_f1_scores[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 'poly' and 'sigmoid' kernels perform a lot worse than the 'linear' and 'rbf' kernels, so they have been omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1...\n",
      "Fold 2...\n",
      "Fold 3...\n",
      "Fold 4...\n",
      "Fold 5...\n",
      "Done!\n",
      "For linear kernel:\n",
      "SVM mean accuracy = 81.30%\n",
      "SVM precisions per activity:\n",
      "['Walking: 97.20%', 'Sitting Down: 94.65%', 'Standing Up: 92.37%', 'Picking up an Object: 55.80%', 'Drinking Water: 58.68%', 'Falling: 94.90%']\n",
      "SVM recalls per activity:\n",
      "['Walking: 98.75%', 'Sitting Down: 94.56%', 'Standing Up: 91.66%', 'Picking up an Object: 61.75%', 'Drinking Water: 51.97%', 'Falling: 93.42%']\n",
      "SVM F1 scores per activity:\n",
      "['Walking: 97.95%', 'Sitting Down: 94.59%', 'Standing Up: 91.87%', 'Picking up an Object: 58.54%', 'Drinking Water: 55.00%', 'Falling: 93.86%']\n",
      "\n",
      "For rbf kernel:\n",
      "SVM mean accuracy = 82.96%\n",
      "SVM precisions per activity:\n",
      "['Walking: 98.14%', 'Sitting Down: 95.46%', 'Standing Up: 92.29%', 'Picking up an Object: 62.35%', 'Drinking Water: 61.65%', 'Falling: 93.85%']\n",
      "SVM recalls per activity:\n",
      "['Walking: 98.44%', 'Sitting Down: 92.95%', 'Standing Up: 90.38%', 'Picking up an Object: 61.72%', 'Drinking Water: 65.14%', 'Falling: 92.29%']\n",
      "SVM F1 scores per activity:\n",
      "['Walking: 98.24%', 'Sitting Down: 94.16%', 'Standing Up: 91.13%', 'Picking up an Object: 62.02%', 'Drinking Water: 63.32%', 'Falling: 92.87%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'rbf']\n",
    "accuracies = np.zeros((5, len(kernels)))\n",
    "precisions = np.zeros((5, len(kernels), num_classes))\n",
    "recalls = np.zeros((5, len(kernels), num_classes))\n",
    "f1_scores = np.zeros((5, len(kernels), num_classes))\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(f\"Fold {i+1}...\")\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    for j, kernel in enumerate(kernels):\n",
    "        svc = SVC(kernel=kernels[j], random_state=42)\n",
    "        svc.fit(x_train_scaled, y_train)\n",
    "        y_pred = svc.predict(x_test_scaled)\n",
    "        accuracies[i,j] = accuracy_score(y_test, y_pred)\n",
    "        precisions[i,j,:] = precision_score(y_test, y_pred, average=None)\n",
    "        recalls[i,j,:] = recall_score(y_test, y_pred, average=None)\n",
    "        f1_scores[i,j,:] = f1_score(y_test, y_pred, average=None)\n",
    "print(\"Done!\")\n",
    "\n",
    "mean_accuracies = np.mean(accuracies, axis=0)\n",
    "mean_precisions = np.mean(precisions, axis=0)\n",
    "mean_recalls = np.mean(recalls, axis=0)\n",
    "mean_f1_scores = np.mean(f1_scores, axis=0)\n",
    "\n",
    "# Print the scores for each kernel\n",
    "for i in range(len(kernels)):\n",
    "    print(f\"For {kernels[i]} kernel:\")\n",
    "    print(f\"SVM mean accuracy = {100*mean_accuracies[i]:.2f}%\")\n",
    "    print(\"SVM precisions per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_precisions[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"SVM recalls per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_recalls[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print(\"SVM F1 scores per activity:\")\n",
    "    print([f\"{activities[j]}: {100*mean_f1_scores[i,j]:.2f}%\" for j in range(num_classes)])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
