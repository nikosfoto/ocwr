{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1754, 2048, 80)\n",
      "(1754,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "x=np.load('scaled_spec_resampled_array.npy')\n",
    "y=np.load('labels_array.npy')-1\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "num_samples, height, width = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "nfft = 2048\n",
    "fs = 128000\n",
    "f_lo = -64000.0\n",
    "f_hi = 63937.5\n",
    "noise_threshold = -83  # dBm (based on the paper's noise threshold)\n",
    "\n",
    "freq_axis=np.linspace(f_lo, f_hi, nfft)\n",
    "print(len(freq_axis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising and feature extraction based on this paper:\n",
    "\n",
    "Y. Kim and H. Ling, \"Human Activity Classification Based on Micro-Doppler Signatures Using a Support Vector Machine,\" in IEEE Transactions on Geoscience and Remote Sensing, vol. 47, no. 5, pp. 1328-1337, May 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_and_extract_features(frequencies, spectrogram, noise_threshold):\n",
    "    # Initialize feature variables\n",
    "    torso_doppler_frequency = []\n",
    "    total_bw_doppler = []\n",
    "    offset_total_doppler = []\n",
    "    bw_without_micro_dopplers = []\n",
    "    normalized_std_doppler = []\n",
    "    high_envelope = []\n",
    "    low_envelope = []\n",
    "\n",
    "    spec_denoised = np.where(spectrogram < noise_threshold, noise_threshold, spectrogram)\n",
    "    for t_index in range(spec_denoised.shape[1]):\n",
    "\n",
    "        column = spec_denoised[:, t_index]\n",
    "        \n",
    "        if np.all(column == noise_threshold):\n",
    "            high_freq = 0\n",
    "            low_freq = 0\n",
    "            peak_freq = 0\n",
    "            total_bw = 0\n",
    "            offset_total = 0\n",
    "            normalized_std = 0\n",
    "        else:\n",
    "            high_freq = frequencies[column > noise_threshold][-1]\n",
    "            low_freq = frequencies[column > noise_threshold][0]\n",
    "            # Torso Doppler Frequency (1)\n",
    "            peak_freq = frequencies[np.argmax(column)]\n",
    "            # Total Bandwidth of the Doppler Signal (2)\n",
    "            total_bw = high_freq-low_freq  # Peak-to-peak value\n",
    "            # Offset of the Total Doppler (3)\n",
    "            offset_total = (high_freq + low_freq) / 2\n",
    "            # Normalized STD of the Doppler Signal Strength (5)\n",
    "            std_doppler = np.std(column[column > noise_threshold])\n",
    "            mean_doppler = np.mean(column[column > noise_threshold])\n",
    "            normalized_std = std_doppler / mean_doppler if mean_doppler != 0 else 0\n",
    "\n",
    "        high_envelope.append(high_freq)\n",
    "        low_envelope.append(low_freq)\n",
    "        torso_doppler_frequency.append(peak_freq)\n",
    "        total_bw_doppler.append(total_bw)\n",
    "        offset_total_doppler.append(offset_total)\n",
    "        normalized_std_doppler.append(normalized_std)\n",
    "\n",
    "    # Bandwidth Without Micro-Dopplers (4)\n",
    "    bw_without_micro_dopplers = np.mean(np.array(sorted(high_envelope)[-5:]) - np.array(sorted(low_envelope)[:5]))\n",
    "\n",
    "    # Period of Limb Motion (6)\n",
    "    peaks, _ = find_peaks(high_envelope, height=np.nanmean(high_envelope))\n",
    "    peak_intervals = np.diff(peaks)\n",
    "    periods = peak_intervals / fs\n",
    "    mean_period = np.mean(periods) if len(periods) > 0 else 0\n",
    "\n",
    "    return [np.mean(torso_doppler_frequency),\n",
    "            np.mean(total_bw_doppler),\n",
    "            np.mean(offset_total_doppler),\n",
    "            bw_without_micro_dopplers,\n",
    "            np.mean(normalized_std_doppler),\n",
    "            mean_period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1754, 6)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from the training set\n",
    "features = []\n",
    "for i in range(num_samples):\n",
    "    features.append(denoise_and_extract_features(freq_axis, x[i,:,:], noise_threshold))\n",
    "features = np.array(features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403, 6)\n",
      "(351, 6)\n",
      "(1403,)\n",
      "(351,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features,y,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1 accuracy: 0.7663817663817664\n",
      "k: 2 accuracy: 0.7635327635327636\n",
      "k: 3 accuracy: 0.7834757834757835\n",
      "k: 4 accuracy: 0.8034188034188035\n",
      "k: 5 accuracy: 0.7891737891737892\n",
      "k: 6 accuracy: 0.7948717948717948\n",
      "k: 7 accuracy: 0.8091168091168092\n",
      "k: 8 accuracy: 0.8034188034188035\n",
      "k: 9 accuracy: 0.7977207977207977\n",
      "k: 10 accuracy: 0.7948717948717948\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Walking       1.00      0.99      0.99        70\n",
      "        Sitting Down       0.84      0.87      0.85        54\n",
      "         Standing Up       0.88      0.88      0.88        66\n",
      "Picking up an Object       0.61      0.75      0.68        61\n",
      "      Drinking Water       0.60      0.46      0.52        65\n",
      "             Falling       0.83      0.83      0.83        35\n",
      "\n",
      "            accuracy                           0.79       351\n",
      "           macro avg       0.79      0.80      0.79       351\n",
      "        weighted avg       0.79      0.79      0.79       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "for k in np.arange(1,11):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    print('k:',k,'accuracy:',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['Walking', 'Sitting Down', 'Standing Up', 'Picking up an Object', 'Drinking Water', 'Falling']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trees: 10 accuracy: 0.8205128205128205\n",
      "trees: 100 accuracy: 0.8575498575498576\n",
      "trees: 250 accuracy: 0.8547008547008547\n",
      "trees: 500 accuracy: 0.8575498575498576\n",
      "trees: 1000 accuracy: 0.8575498575498576\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Walking       0.99      0.96      0.97        70\n",
      "        Sitting Down       0.93      0.96      0.95        54\n",
      "         Standing Up       0.86      0.97      0.91        66\n",
      "Picking up an Object       0.70      0.74      0.72        61\n",
      "      Drinking Water       0.72      0.65      0.68        65\n",
      "             Falling       1.00      0.89      0.94        35\n",
      "\n",
      "            accuracy                           0.86       351\n",
      "           macro avg       0.87      0.86      0.86       351\n",
      "        weighted avg       0.86      0.86      0.86       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "for trees in [10,100,250,500,1000]:\n",
    "    rf=RandomForestClassifier(n_estimators=trees)\n",
    "    rf.fit(x_train,y_train)\n",
    "    y_pred=rf.predict(x_test)\n",
    "    print('trees:',trees,'accuracy:',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['Walking', 'Sitting Down', 'Standing Up', 'Picking up an Object', 'Drinking Water', 'Falling']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.8376068376068376\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Walking       1.00      0.96      0.98        70\n",
      "        Sitting Down       0.92      1.00      0.96        54\n",
      "         Standing Up       0.88      0.95      0.91        66\n",
      "Picking up an Object       0.64      0.70      0.67        61\n",
      "      Drinking Water       0.67      0.55      0.61        65\n",
      "             Falling       0.97      0.89      0.93        35\n",
      "\n",
      "            accuracy                           0.84       351\n",
      "           macro avg       0.84      0.84      0.84       351\n",
      "        weighted avg       0.84      0.84      0.83       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb=XGBClassifier(n_estimators=250)\n",
    "xgb.fit(x_train,y_train)\n",
    "y_pred=xgb.predict(x_test)\n",
    "print('XGBoost accuracy:',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['Walking', 'Sitting Down', 'Standing Up', 'Picking up an Object', 'Drinking Water', 'Falling']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.8290598290598291\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Walking       1.00      0.93      0.96        70\n",
      "        Sitting Down       0.90      0.96      0.93        54\n",
      "         Standing Up       0.90      0.95      0.93        66\n",
      "Picking up an Object       0.62      0.64      0.63        61\n",
      "      Drinking Water       0.65      0.62      0.63        65\n",
      "             Falling       0.97      0.91      0.94        35\n",
      "\n",
      "            accuracy                           0.83       351\n",
      "           macro avg       0.84      0.84      0.84       351\n",
      "        weighted avg       0.83      0.83      0.83       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=42)\n",
    "svc.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred = svc.predict(x_test_scaled)\n",
    "print('SVM accuracy:',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['Walking', 'Sitting Down', 'Standing Up', 'Picking up an Object', 'Drinking Water', 'Falling']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
